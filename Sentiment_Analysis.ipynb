{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk2DPrGviClB",
        "colab_type": "text"
      },
      "source": [
        "# Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RESnGByoE2Xn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82f3a029-35dc-4f70-9ba1-eceda3461223"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d-bQXT5dGIv",
        "colab_type": "text"
      },
      "source": [
        "# Importing Data tfrom files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZl2ivxuEmYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "231c214f-b5e5-452e-f62f-2a222940c333"
      },
      "source": [
        "!unzip data.zip  #Run this if you are using Google colabratory"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "replace data/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/.DS_Store          \n",
            "replace data/amazon_cells_labelled.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/amazon_cells_labelled.txt  \n",
            "replace data/imdb_labelled.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/imdb_labelled.txt  \n",
            "replace data/readme.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/readme.txt         \n",
            "replace data/yelp_labelled.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/yelp_labelled.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG_i9OL6DZ1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "filepath_dict = {'yelp':   'data/yelp_labelled.txt',\n",
        "                 'amazon': 'data/amazon_cells_labelled.txt',\n",
        "                 'imdb':   'data/imdb_labelled.txt'}\n",
        "\n",
        "df_list = []\n",
        "for source, filepath in filepath_dict.items():\n",
        "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
        "    df['source'] = source  # Add another column filled with the source name\n",
        "    df_list.append(df)\n",
        "\n",
        "df = pd.concat(df_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TfFxmlqdUnE",
        "colab_type": "text"
      },
      "source": [
        "# Splitting Data for Test and Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn1gt0gdEsdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = df['sentence']    #features\n",
        "y = df['label']               #Labels\n",
        "\n",
        "# Train-test split\n",
        "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rlEkhhglUer",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize and preparation of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMiybZtgE48J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize words\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(sentences_train)\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tMUYz34E89o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKRz-lWjFDRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad sequences with zeros\n",
        "\n",
        "maxlen = 200\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdHLgMgzlgFS",
        "colab_type": "text"
      },
      "source": [
        "# Buid Keras Model and Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcCcij7kEzVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Main settings\n",
        "epochs = 10\n",
        "embedding_dim = 50\n",
        "\n",
        "output_file = 'data/output.txt'\n",
        "# Parameter grid for grid search\n",
        "param_grid = dict(num_filters=[64],\n",
        "                  kernel_size=[7],\n",
        "                  vocab_size=[vocab_size],\n",
        "                  embedding_dim=[embedding_dim],\n",
        "                  maxlen=[maxlen])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhFDscz7FLIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(num_filters, kernel_size, vocab_size, embedding_dim, maxlen):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "    model.add(layers.Conv1D(num_filters, kernel_size, activation='relu'))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(10, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKbQB6DCFPln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KerasClassifier(build_fn=create_model,epochs=epochs, batch_size=10,verbose=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVXfgUITFTG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
        "                          cv=4, verbose=1, n_iter=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlinjBIWFdnj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "dc78ce3d-e37a-475f-88cb-83be135fab8c"
      },
      "source": [
        "grid_result = grid.fit(X_train, y_train)  #Took Around 1.6min  to finish in Google colab"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 1 is smaller than n_iter=5. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0711 15:20:44.767977 140502108546944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0711 15:20:44.784341 140502108546944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0711 15:20:44.788620 140502108546944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0711 15:20:44.853814 140502108546944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0711 15:20:44.876991 140502108546944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0711 15:20:44.886334 140502108546944 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0711 15:20:45.113069 140502108546944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.5min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMyj1urLlpjs",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-ngYxD_FhJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate testing set\n",
        "\n",
        "test_accuracy = grid.score(X_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYNGY8lxFpbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "b4685e24-7fcb-478a-a8cf-4d540c5f4f94"
      },
      "source": [
        "# saving the best fit parameters\n",
        "\n",
        "prompt=input(\"Enter[y/n]\")\n",
        "if prompt.lower() in {'y', 'true', 'yes'}:\n",
        "  with open(output_file, 'a') as f:\n",
        "    s = ('data set\\nBest Accuracy : ''{:.4f}\\n{}\\nTest Accuracy : {:.4f}\\n\\n')\n",
        "    output_string = s.format(\n",
        "        grid_result.best_score_,\n",
        "        grid_result.best_params_,\n",
        "        test_accuracy)\n",
        "    print(output_string)\n",
        "    f.write(output_string)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter[y/n]y\n",
            "data set\n",
            "Best Accuracy : 0.8151\n",
            "{'vocab_size': 4603, 'num_filters': 64, 'maxlen': 200, 'kernel_size': 7, 'embedding_dim': 50}\n",
            "Test Accuracy : 0.8355\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtvgsPGtl55G",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWdsaHIBK_gV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5c88cef1-2c9d-4346-c248-80d6034f1dc7"
      },
      "source": [
        "\n",
        "labels=[\"Negative\", \"Positive\"]\n",
        "a=[\"The hotel was under renovation and the smeel was unbeareable\"]\n",
        "a_series=pd.Series(a)\n",
        "a_tokenizer=tokenizer.texts_to_sequences(a_series)\n",
        "\n",
        "# Pad sequences with zeros\n",
        "a_pad = pad_sequences(a_tokenizer, padding='post', maxlen=maxlen)\n",
        "k=-1\n",
        "for i in a_pad:\n",
        "  k+=1\n",
        "  print('Sentence:' + str(a[k]))\n",
        "  prediction=grid.predict(np.array([i]))\n",
        "  predict_label=labels[prediction[0][0]]\n",
        "  print('Prediction: '+ str(predict_label))\n",
        "  print()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence:The hotel was under renovation and the smeel was unbeareable\n",
            "Prediction:Negative\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3L3hvLup4mN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}